{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'chin': [(330, 615), (325, 644), (328, 673), (340, 701), (352, 728), (365, 755), (379, 781), (397, 802), (425, 808), (462, 803), (504, 790), (545, 770), (576, 741), (594, 704), (598, 660), (597, 617), (595, 575)], 'left_eyebrow': [(319, 572), (323, 553), (338, 544), (357, 544), (375, 551)], 'right_eyebrow': [(409, 540), (437, 525), (469, 516), (503, 522), (528, 540)], 'nose_bridge': [(396, 587), (392, 605), (387, 624), (382, 643)], 'nose_tip': [(378, 672), (388, 675), (398, 675), (412, 670), (425, 666)], 'left_eye': [(342, 608), (351, 595), (367, 592), (383, 603), (369, 609), (353, 612)], 'right_eye': [(445, 589), (461, 573), (480, 570), (500, 575), (486, 587), (466, 591)], 'top_lip': [(371, 722), (376, 708), (387, 699), (397, 701), (409, 697), (433, 702), (465, 710), (454, 712), (412, 714), (400, 716), (391, 716), (378, 720)], 'bottom_lip': [(465, 710), (439, 730), (418, 741), (404, 744), (394, 745), (381, 738), (371, 722), (378, 720), (391, 719), (400, 719), (413, 716), (454, 712)]}]\n"
     ]
    }
   ],
   "source": [
    "image = face_recognition.load_image_file('E:/Courses/Face Recognition/FF/known/3.jpeg')\n",
    "face_landmarks = face_recognition.face_landmarks(image)\n",
    "print(face_landmarks)\n",
    "#convert numpy array image into pil image\n",
    "pil_image = Image.fromarray(image)\n",
    "#convert pil_image to draw object\n",
    "d = ImageDraw.Draw(pil_image)\n",
    "\n",
    "for face_landmark in face_landmarks:\n",
    "    #joint each face_landmark points\n",
    "    d.line(face_landmark['chin'], fill=(255,0,0), width=2)\n",
    "    d.line(face_landmark['left_eyebrow'], fill=(255,0,0), width=2)\n",
    "    d.line(face_landmark['right_eyebrow'], fill=(255,0,0), width=2)\n",
    "    d.line(face_landmark['nose_bridge'], fill=(255,0,0), width=2)\n",
    "    d.line(face_landmark['nose_tip'], fill=(255,0,0), width=2)\n",
    "    d.line(face_landmark['left_eye'], fill=(255,0,0), width=2)\n",
    "    d.line(face_landmark['right_eye'], fill=(255,0,0), width=2)\n",
    "    d.line(face_landmark['top_lip'], fill=(255,0,0), width=2)\n",
    "    d.line(face_landmark['bottom_lip'], fill=(255,0,0), width=2)\n",
    "    \n",
    "pil_image.show()\n",
    "pil_image.save('E:/Courses/Face Recognition/FF/known/face_landmarks.jpeg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
